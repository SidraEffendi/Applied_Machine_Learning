{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OWTe9VS3_b11"
   },
   "source": [
    "## SI 670 Applied Machine Learning, Week 4:  Multi-class Classification, SVM, Data Leakage (Due Wednesday 09/28/2022 11:59pm)\n",
    "\n",
    "For this assignment, you will be practicing various machine learning operations in scikit-learn related to linear regression, polynomial feature expansion and underfitting/overfitting.\n",
    "\n",
    "* This homework is worth 100 points in total. Correct answers and code receive full credit, but partial credit will be awarded if you have the right idea even if your final answers aren't quite right.\n",
    "\n",
    "* Submit your completed notebook file to the Canvas site - **IMPORTANT**: please name your submitted file `si670f22-hw4-youruniqname.ipynb`\n",
    "\n",
    "* Any file submitted after the deadline will be marked as late. Please consult the syllabus regarding late submission policies. You can submit the homework as many time as you want, but only your latest submission will be graded.\n",
    "\n",
    "* As a reminder, the notebook code you submit must be your own work. Feel free to discuss general approaches to the homework with classmates. If you end up forming more of a team discussion on multiple questions, please include the names of the people you worked with at the top of your notebook file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m6okIS2jCBg6"
   },
   "source": [
    "### Collaborators, if any:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uASDnXuXCBg7"
   },
   "source": [
    "### Question 1 (20 points)\n",
    "\n",
    "Please write the answers as well as your derivation process of the following questions. You can use either LaTeX or python code to represent your answer. For example, if you want to present <$x_1^2$>, in the LaTeX format you should write <(dollar sign) x_1^2 (dollar sign)>; in the python code format you should write <\\`x_1\\*\\*2\\`>. See [here](https://csrgxtu.github.io/2015/03/20/Writing-Mathematic-Fomulars-in-Markdown/) for how to represent more mathmatical symbols in LaTeX format.\n",
    "\n",
    "*Note: This question 1 does not require coding.*\n",
    "\n",
    "<!-- #### (a) (10 points) \n",
    "\n",
    "If you have data with features $(x_1, x_2)$, what will be the set of the expanded features after you apply the `PolynomialFeatures` transformation with `degree=3` on it? The order of the features does not matter in your answer.\n",
    "\n",
    "#### (b) (10 points) \n",
    "The main metric we have been using to measure the quality of regression models is $R^2$, which is defined as, for n data points, $R^2 = 1 -  \\frac{\\sum_{i=1}^n(\\hat{y}_i - y_i)^2}{\\sum_{i=1}^n(y_i - \\bar{y})^2}$, where $y_i, \\hat{y}_i$ are the label and prediction of data point i, and $\\bar{y} = \\frac{1}{n}\\sum_{i=1}^n y_i$. We denote $\\frac{1}{n}\\sum_{i=1}^n(\\hat{y}_i - y_i)^2$ as *Unexplained Variation* and $\\frac{1}{n}\\sum_{i=1}^n(y_i - \\bar{y})^2$ as *Total Variation*. \n",
    "\n",
    "Given 5 data points with labels (1, 3, 2, -4, 6) and two classifiers A and B, suppose the predictions of A are (1.1, 1.4, 1.3, -2, 2) and the predictions of B are (1.7, 1.3, 0.3, 2, 3). Please calculate and report the *Unexplained Variation*, *Total Variation*, and *$R^2$* for classifiers A and B respectively.  -->\n",
    "\n",
    "#### (a) (5 points)\n",
    "Suppose that $w = (3, 4)$ for an SVM decision boundary. What is the margin $M$?\n",
    "\n",
    "#### (a) (10 points)\n",
    "Suppose that $(3, 2)$ is a support vector for the SVM above, and its label is $+1$. What is the $b$ for the SVM decision boundary? (Hint: think about the positive plane)\n",
    "\n",
    "#### (b) (5 points)\n",
    "You are given 3 data points with two features $x_1$ and $x_2$ and one label $Y$ as follows,\n",
    "\n",
    "|  X1\t| X2 \t| Y \t |\n",
    "|----\t|----\t|----\t |\n",
    "|   1\t|  1  | +1   |\n",
    "| 0.7 |  3 \t| -1   |\n",
    "|   2 | 0.5 | +1   |\n",
    "\n",
    "Suppose you have a linear classification model where $w = (0.5, 0)$. What is the hinge loss with L2 regularization for this model?\n",
    "\n",
    "<!-- You are given 3 data points with two features $x_1$ and $x_2$ and one label $Y$ as follows,\n",
    "\n",
    "|    X1\t| X2 \t| Y \t|\n",
    "|----\t|----\t|----\t|\n",
    "|   1\t|   1 \t| 1.05 \t|\n",
    "|   0.7 |  3 \t| 0.81 \t|\n",
    "|   2   |  0.5 \t| 2.045 |\n",
    "\n",
    "Suppose you have a linear regression model: $\\hat{y} = w_1 x_1 + w_2 x_2$, please calculate and report the hinge loss, the L1 regularization, and the L2 regularization terms for each of the following linear models:\n",
    "\n",
    "(i) $w_1 = 1, w_2 = 0$\n",
    "\n",
    "(ii) $w_1 = 1, w_2 = 0.02$\n",
    "\n",
    "If you set the regularization coefficient $\\alpha=1$, which of the above two weights is preferred by the Lasso and which is preferred by Ridge regression? Could you use this example to explain why Lasso prefers sparse models? -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ysXqAEOECBg8"
   },
   "source": [
    "#### Answer 1(a)\n",
    "\n",
    "Write your answer to 1(a) here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lK2MJRK9CBg8"
   },
   "source": [
    "#### Answer 1(b)\n",
    "\n",
    "Write your answer to 1(b) here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WqIsI5Dgfd3F"
   },
   "source": [
    "#### Answer 1(c)\n",
    "\n",
    "Write your answer to 1(c) here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qbBHuwtjh8Du"
   },
   "source": [
    "### Question 2 (40 points)\n",
    "\n",
    "First use `MinMaxScaler` to scale the breast cancer data and then use `GridSearchCV` to search the `kernel`, `C`, and `gamma` parameters for `SVC`. Be careful about the data leakage issues. Please return the best hyper-parameters on cross-validation and the test score associated with the these hyper-parameters.\n",
    "\n",
    "Please search the `kernel` from ('linear', 'rbf'), `C` from (0.1, 1, 10, 100), `gamma` from (0.1, 1, 10, 100). And please apply `random_state=0` in both `train_test_split`.\n",
    "\n",
    "*This function should a return a tuple with four numbers, i.e. `(best_kernel, best_C, best_gamma, test_score)`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "\n",
    "# cancer dataset\n",
    "(X_cancer, y_cancer) = load_breast_cancer(return_X_y = True)\n",
    "#split into training and test and validation sets\n",
    "X_train, X_test, y_train, y_test =train_test_split(X_cancer, y_cancer, random_state=0, test_size=0.25)\n",
    "\n",
    "svc = SVC().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = mm.transform(X_train)\n",
    "X_test_scaled = mm.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC().fit(X_train_scaled, y_train)\n",
    "svc.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.972027972027972"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC().fit(X_train_scaled, y_train)\n",
    "svc.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'kernel':('linear', 'rbf'), 'C':[0.1, 1, 10, 100], 'gamma':[0.1, 1, 10, 100]}\n",
    "clf = GridSearchCV(svc, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9835680751173709"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_clf = clf.fit(X_train_scaled, y_train)\n",
    "svc_clf.score(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a =svc_clf.score(X_test_scaled, y_test)\n",
    "# svc_clf.cv_results_['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'C': 1, 'gamma': 1, 'kernel': 'rbf'}, 0.972027972027972)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_clf.cv_results_['params'][svc_clf.best_index_], svc_clf.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svc_clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_C', 'param_gamma', 'param_kernel', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cv_results_._['params'][search.best_index_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "       1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC().fit(X_train, y_train)\n",
    "svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "XecW8XxcCBg9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('rbf', 1, 1, 0.9736842105263158)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_two():\n",
    "    from sklearn.datasets import load_breast_cancer\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    import numpy as np\n",
    "    \n",
    "    # cancer dataset\n",
    "    (X_cancer, y_cancer) = load_breast_cancer(return_X_y = True)\n",
    "    #split into training and test and validation sets\n",
    "    X_train, X_test, y_train, y_test =train_test_split(X_cancer, y_cancer, random_state=0, test_size=0.2)\n",
    "    \n",
    "    #scaling\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = mm.fit_transform(X_train)\n",
    "    X_test_scaled = mm.transform(X_test)\n",
    "    \n",
    "    svc = SVC().fit(X_train_scaled, y_train)\n",
    "    svc.score(X_test_scaled, y_test)\n",
    "    \n",
    "    parameters = {'kernel':('linear', 'rbf'), 'C':[0.1, 1, 10, 100], 'gamma':[0.1, 1, 10, 100]}\n",
    "    clf = GridSearchCV(svc, parameters)\n",
    "    \n",
    "    svc_clf = clf.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    best_kernel =  svc_clf.cv_results_['params'][svc_clf.best_index_]['kernel']\n",
    "    best_C = svc_clf.cv_results_['params'][svc_clf.best_index_]['C']\n",
    "    best_gamma = svc_clf.cv_results_['params'][svc_clf.best_index_]['gamma']\n",
    "    test_score = svc_clf.score(X_test_scaled, y_test)\n",
    "\n",
    "    return best_kernel, best_C, best_gamma, test_score\n",
    "\n",
    "answer_two()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wZct0MdZCBg-"
   },
   "source": [
    "### Question 3 (40 points)\n",
    "\n",
    "Suppose you have a dataset with some missing values and you know the values are not missing at random and the probability of missing is related to the values themselves. For example, people with higher\n",
    "earnings may be less likely to reveal them. \n",
    "\n",
    "#### (a) (5 points) In this case, what would happen when imputing the missing values with the mean strategy?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SWLX2x15CBg-"
   },
   "source": [
    "#### Answer 3(a)\n",
    "\n",
    "Write your anwer here.\n",
    "then we will lose an important feature associated with people who earn more. This severly affects a classification like "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "I4VxfnNbCBg_",
    "outputId": "058af9fe-378e-4ed9-a8a0-1022d2ed19c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The performance based on the full data: 0.923\n"
     ]
    }
   ],
   "source": [
    "# Please run this cell first before doing question 3(b)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "d = {}\n",
    "for i in range(len(cancer.feature_names)):\n",
    "    d[cancer.feature_names[i]] = cancer.data[:, i]\n",
    "d['target'] = cancer.target\n",
    "df = pd.DataFrame(d)\n",
    "\n",
    "\n",
    "X = df[['mean concave points', 'worst concave points']]\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(X), np.array(y), random_state=0)\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "print('The performance based on the full data: {:.3f}'.format(lr.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "\n",
    "n_samples = X_train.shape[0]\n",
    "X_train_missing = X_train.copy()\n",
    "u = rng.uniform(low=0.3, high=1, size=(n_samples,))\n",
    "X_train_missing[np.where(u < X_train[:, 0])[0], 0] = np.nan\n",
    "u = rng.uniform(low=0.3, high=1, size=(n_samples,))\n",
    "X_train_missing[np.where(u < X_train[:, 1])[0], 1] = np.nan\n",
    "\n",
    "n_samples = X_test.shape[0]\n",
    "X_test_missing = X_test.copy()\n",
    "u = rng.uniform(low=0.3, high=1, size=(n_samples,))\n",
    "X_test_missing[np.where(u < X_test[:, 0])[0], 0] = np.nan\n",
    "u = rng.uniform(low=0.3, high=1, size=(n_samples,))\n",
    "X_test_missing[np.where(u < X_test[:, 1])[0], 1] = np.nan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKaez89eCBhA"
   },
   "source": [
    "#### (b) (10 points) \n",
    "\n",
    "Please impute the missing values using `SimpleImputer` with `strategy='mean'`. Then fit a LogisticRegression with default hyper-parameters, and return the imputed data and the test score.\n",
    "\n",
    "\n",
    "*This function should a return a tuple of two arrays and one number: `(X_train_imputed, X_test_imputed, test_score)`.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "dVp8Z5-HCBhA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8461538461538461\n"
     ]
    }
   ],
   "source": [
    "def answer_three_b():\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    \n",
    "    # YOUR CODE HERE.\n",
    "    imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "#     imp_mean.fit(X_train)\n",
    "    X_train_imputed = imp_mean.fit_transform(X_train_missing)\n",
    "    X_test_imputed = imp_mean.transform(X_test_missing)\n",
    "    \n",
    "    linreg = LogisticRegression().fit(X_train_imputed, y_train)\n",
    "#     linreg.fit(X_train_imputed, y_train)\n",
    "    test_score = linreg.score(X_test_imputed, y_test)\n",
    "    print(test_score)\n",
    "    \n",
    "    return (X_train_imputed, X_test_imputed, test_score)\n",
    "\n",
    "answer_three_b()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-4AZeLw8CBhB"
   },
   "source": [
    "#### (c) (10 points) \n",
    "\n",
    "Please impute the missing values using `SimpleImputer` with `strategy='mean'` and `add_indicator=True`. Then fit a LogisticRegression with default hyper-parameters, and return the imputed data and the test score.\n",
    "\n",
    "\n",
    "*This function should a return a tuple of two arrays and one number: `(X_train_imputed, X_test_imputed, test_score)`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "LmdhiJbzCBhB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9090909090909091\n"
     ]
    }
   ],
   "source": [
    "def answer_three_c():\n",
    "    from sklearn.impute import SimpleImputer\n",
    "\n",
    "    imp_mean_ind = SimpleImputer(missing_values=np.nan, strategy='mean', add_indicator=True)\n",
    "#     imp_mean_ind.fit(X_train)\n",
    "    X_train_imputed_ind = imp_mean_ind.fit_transform(X_train_missing)\n",
    "    X_test_imputed_ind = imp_mean_ind.transform(X_test_missing)\n",
    "    \n",
    "    linreg = LogisticRegression().fit(X_train_imputed_ind, y_train)\n",
    "#     linreg.fit(X_train_imputed, y_train)\n",
    "    test_score = linreg.score(X_test_imputed_ind, y_test)\n",
    "#     print(test_score)\n",
    "\n",
    "#     return (X_train_imputed, X_test_imputed, test_score)\n",
    "\n",
    "answer_three_c()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bj_fNz7hCBhC"
   },
   "source": [
    "#### (d) (5 points) \n",
    "\n",
    "Why is adding the indicator helpful when the missing values are \"missing not at random\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UI4tLDWZCBhC"
   },
   "source": [
    "#### Answer 3(d)\n",
    "\n",
    "Having the indicator here is helpful because the values are missing based on certain conditions or we cansay values are missing systematically, which itself serves as a feature, improving the Logistic Regression prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8zIkVmQJCBhD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
