{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OWTe9VS3_b11"
   },
   "source": [
    "## SI 670 Applied Machine Learning, Week 3: Cross Validation, Logistic Regression and Evaluation (Due Wednesday Sept 21, 2022 11:59pm)\n",
    "\n",
    "For this assignment, you will be exercising on questions related to Logistic regression, Dummy classifiers, and cross-validation.\n",
    "\n",
    "* This homework is worth 100 points in total. Correct answers and code receive full credit, but partial credit will be awarded if you have the right idea even if your final answers aren't quite right.\n",
    "\n",
    "* Submit your completed notebook file to the Canvas site - **IMPORTANT**: please name your submitted file `si670f22-hw3-youruniqname.ipynb`\n",
    "\n",
    "* Any file submitted after the deadline will be marked as late. Please consult the syllabus regarding late submission policies. You can submit the homework as many time as you want, but only your latest submission will be graded.\n",
    "\n",
    "* As a reminder, the notebook code you submit must be your own work. Feel free to discuss general approaches to the homework with classmates. If you end up forming more of a team discussion on multiple questions, please include the names of the people you worked with at the top of your notebook file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 (20 points)\n",
    "\n",
    "This question asks you to explore the relationship between the distribution of cross-validation scores vs the data size. \n",
    "\n",
    "Please use a 'for' loop to repeat the following steps with `n` varying from `[100, 500, 1000, 5000, 10000]`:\n",
    "1. Generate synthetic data `(X_F1, y_F1)` using `make_friedman1` with `n_samples=n, n_features=7, random_state=0`;\n",
    "2. Create a `LinearRegression` model\n",
    "3. Apply `cross_val_score` to the model and generated data and use three-fold cross-validation.\n",
    "4. Calculate the mean and std of the returned `cv_scores` across the 3 cross-validation folds.\n",
    "\n",
    "Store the mean and std of the `cv_scores` in lists `cv_scores_mean` and `cv_scores_std` respectively. Do you see the std increasing or decreasing? And why? \n",
    "\n",
    "*This function should return a tuple of two lists `(cv_scores_mean, cv_scores_std)`, where both of them should have length 5.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_one():\n",
    "    import numpy as np\n",
    "    from sklearn.datasets import make_friedman1\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    \n",
    "    cv_scores_mean = []\n",
    "    cv_scores_std = []\n",
    "    # Your code here\n",
    "    \n",
    "    return (cv_scores_mean, cv_scores_std)\n",
    "\n",
    "# answer_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_pUE4abw2eQ"
   },
   "source": [
    "Now, you will train a logistic regression classifier models and evaluate how effectively it  predicts instances of fraud using data based on [this dataset from Kaggle](https://www.kaggle.com/dalpozz/creditcardfraud). Then you'll perform a grid search to find optimal parameters. \n",
    " \n",
    "Each row in `fraud_data.csv` corresponds to a credit card transaction. Features include confidential variables `V1` through `V28` as well as `Amount` which is the amount of the transaction. \n",
    " \n",
    "The target is stored in the `class` column, where a value of 1 corresponds to an instance of fraud and 0 corresponds to an instance of not fraud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9sZdd_dXOF6I"
   },
   "outputs": [],
   "source": [
    "# # run this cell if you are using Colab\n",
    "\n",
    "# !rm -rf fraud_data.csv\n",
    "\n",
    "# import io\n",
    "\n",
    "# from google.colab import files as colab_files\n",
    "# uploaded = colab_files.upload()\n",
    "# files = {'fraud_data.csv': io.BytesIO(uploaded['fraud_data.csv'])}\n",
    "\n",
    "# # upload 'fraud_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qkk268H3OF6J"
   },
   "outputs": [],
   "source": [
    "# run this cell if you are using Jupyter\n",
    "files = {'fraud_data.csv': 'fraud_data.csv'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XyRpHK8dOF6J"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(files['fraud_data.csv'])\n",
    "\n",
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "itE2L8t4w2ee"
   },
   "source": [
    "### Question 2 (20 points)\n",
    "\n",
    "Using `X_train`, `X_test`, `y_train`, and `y_test` (as defined above), train a dummy classifier that classifies everything as the majority class of the training data. What is the accuracy of this classifier? What is the recall?\n",
    "\n",
    "Then train a LogisticRegression classifier with C=1. What is the accuracy? What is the recall?\n",
    "\n",
    "*This function should a return a tuple with four floats, i.e. `(dummy_accuracy, dummy_recall, lr_accuracy, lr_recall)`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8qd9c7olOF6L"
   },
   "outputs": [],
   "source": [
    "def answer_two():\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return dummy_accuracy, dummy_recall, lr_accuracy, lr_recall\n",
    "\n",
    "# answer_two()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hzgEUQqLOF6M"
   },
   "source": [
    "### Question 3 (20 points)\n",
    "\n",
    "Fit the LogisticRegression with `C` varying from `[[0.1, 1, 10]` and report the accuracy, precision, recall, and F1 scores for each choice of `C`.\n",
    "\n",
    "*This function should a return a tuple with four lists, i.e. `(accuracy_list, precision_list, recall_list, f1_list)`, and each list should contain 3 numbers, one per choice of C*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FQhWIu5YOF6N"
   },
   "outputs": [],
   "source": [
    "def answer_three():\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    return accuracy_list, precision_list, recall_list, f1_list\n",
    "\n",
    "# answer_three()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mPLuNfuBOF6N"
   },
   "source": [
    "### Question 4 (20 points)\n",
    "\n",
    "Train a logistic regression classifier with `C=10` using X_train and y_train.\n",
    "\n",
    "For the logistic regression classifier, create (1) a precision-recall curve and (2) an ROC curve using y_test and the probability estimates for X_test (probability it is fraud).\n",
    "\n",
    "Looking at the precision recall curve, what is the recall when the precision is `0.75`?\n",
    "\n",
    "Looking at the ROC curve, what is the true positive rate when the false positive rate is `0.16`?\n",
    "\n",
    "*This function should return a tuple with two floats, i.e. `(recall_at_p75, tpr_at_fpr16)`.*\n",
    "*You should also include code that uses the scikit-learn (sklearn.metrics) functions precision_recall_curve and roc_curve to generate the precision/recall and ROC curves above*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P7O1_7ZaOF6O"
   },
   "outputs": [],
   "source": [
    "def answer_four():\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    return recall_at_p75, tpr_at_fpr16\n",
    "\n",
    "# answer_four()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7l9PMRZnOF6O"
   },
   "source": [
    "### Question 5 (20 Points)\n",
    "\n",
    "Suppose you have trained a classifier distinguishing Benign vs Malignant cancers. And the confusion matrix of your classifier is given below.\n",
    "\n",
    "|      \t| Predicted: Benign \t| Predicted: Malignant \t|\n",
    "|:----:\t|----\t|----\t|\n",
    "| Actual: Benign \t|    10000\t|   100 \t|\n",
    "| Actual: Malignant  \t|    200\t|   10 \t|\n",
    "\n",
    "### Question 5 (a) (10 points) \n",
    "If we assume Benign is the positive class and Malignant is the negative class, what are the precision and recall for Benign? If we assume Malignant is the positive class and Benign is the negative class, what are the precision and recall for Malignant?\n",
    "\n",
    "*This function should return a tuple of four float numbers: `(precision_benign, recall_benign, precision_malignant, recall_malignant)`. You can calculate these scores either by coding, or by hand using the correct formulas for precision and recall.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l1F7nE48OF6P"
   },
   "outputs": [],
   "source": [
    "def answer_five_a():\n",
    "    \n",
    "    # Coding or manually calculating the precision and recall scores here. \n",
    "\n",
    "    return precision_benign, recall_benign, precision_malignant, recall_malignant\n",
    "\n",
    "# answer_five_a()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rry-cXSjOF6P"
   },
   "source": [
    "### Question 5 (b) (10 points) \n",
    "If you have another classifier with the following confusion matrix, which classifier do you prefer and why? (Hint: calculate the precision and recall scores for this classifier and compare with the previous classifier, considering what the relative costs are for each type of mistake.)\n",
    "\n",
    "|      \t| Predicted: Benign \t| Predicted: Malignant \t|\n",
    "|:----:\t|----\t|----\t|\n",
    "| Actual: Benign \t|    7000\t|   3100 \t|\n",
    "| Actual: Malignant  \t|    30\t|   180 \t|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lh7SYTtJOF6P"
   },
   "source": [
    "#### Answer to question 4 (b)\n",
    "\n",
    "Write your answer here."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "si670f21_hw_3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
